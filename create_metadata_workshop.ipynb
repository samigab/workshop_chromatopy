{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Course Monitoring of the PAD-Catalyzed Decarboxylation of *p*-Coumaric Acid Using HPLC-UV Analysis\n",
    "\n",
    "In subproject SP7, the acquisition and analysis of time-course data are fundamental to understanding enzyme kinetics and evaluating reaction efficiency. In particular, chromatic (UV-visible absorbance) data obtained through high-performance liquid chromatography (HPLC) are utilized to quantify substrate depletion and product formation over time.\n",
    "\n",
    "## Analytical Methodology\n",
    "\n",
    "All chromatographic measurements were performed using an **Agilent 1100 HPLC system** equipped with a diode array detector (DAD). This setup allows for simultaneous monitoring of multiple wavelengths, enabling detection of both the substrate and the product in the same chromatographic run. The reaction under investigation involves the enzymatic decarboxylation of *p*-coumaric acid, catalyzed by **Phenolic Acid Decarboxylase (PAD)**, yielding vinylphenol and carbon dioxide:\n",
    "\n",
    "C9H8O3 â”€â”€(PAD)â”€â”€â–º C8H8O + CO2\n",
    "\n",
    "\n",
    "- **Substrate:** *p*-Coumaric acid (4-hydroxycinnamic acid)  \n",
    "- **Product:** Vinylphenol (4-vinylphenol)\n",
    "\n",
    "This biotransformation is a common model reaction in enzymatic decarboxylation studies, given its relevance in microbial metabolism of plant-derived phenolic acids.\n",
    "\n",
    "## Calibration and Detection Parameters\n",
    "\n",
    "To enable quantification, calibration curves for *p*-coumaric acid were established using standard solutions at concentrations of **2 mM**, **4 mM**, and **10 mM**. These were measured by their UV absorption characteristics under identical HPLC conditions to those used for the enzymatic reaction samples.\n",
    "\n",
    "- *p*-Coumaric acid:\n",
    "  - **Î»max:** 282 nm  \n",
    "  - **Retention time:** ~1.5 min\n",
    "\n",
    "- Vinylphenol:\n",
    "  - **Î»max:** 237 nm  \n",
    "  - **Retention time:** ~4.9 min\n",
    "\n",
    "\n",
    "## Experimental Setup for Time-Course Measurement\n",
    "\n",
    "The enzymatic reaction was initiated with an initial substrate concentration of **30 mM *p*-coumaric acid** in solution. The reaction mixture also contained **38.8 mg/mL of PAD enzyme**, assumed to be active under the experimental conditions.\n",
    "\n",
    "**Your info here**: (Buffer composition, pH, temperature, total reaction volume, and mixing conditions are required to accurately interpret the kinetic data and assess reaction robustness.)\n",
    "\n",
    "Samples were withdrawn at predefined time points:\n",
    "\n",
    "0, 15, 30, 60, 120, and 240 minutes\n",
    "\n",
    "At each time point, aliquots were taken and analyzed via HPLC to monitor changes in substrate and product concentration over time.\n",
    "\n",
    "**Your info here**: (Clarification is needed on whether enzymatic reactions were quenchedâ€”e.g., by acidification or heat denaturationâ€”prior to injection into the HPLC system.)\n",
    "\n",
    "This time-course dataset enables the construction of concentration-vs-time plots for both substrate depletion and product accumulation, which are critical for subsequent kinetic modeling. Through such analysis, initial reaction velocities, turnover numbers, and potential substrate inhibition or enzyme deactivation phenomena can be identified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make sure chromatopy is installed:\n",
    "# pip install git+https://github.com/FAIRChemistry/chromatopy.git\n",
    "\n",
    "# Then try importing:\n",
    "try:\n",
    "    from chromatopy import ChromAnalyzer\n",
    "    from chromatopy.units import *\n",
    "    import chromatopy as cp\n",
    "    from chromatopy.tools.utility import visualize_enzymeml \n",
    "    from chromatopy.ioutils.enzymeml import to_enzymeml\n",
    "    from pyenzyme import EnzymeMLDocument\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing chromatopy: {e}\")\n",
    "    print(\"Make sure chromatopy is installed correctly with: pip install git+https://github.com/FAIRChemistry/chromatopy.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First set up the path of your data:\n",
    "You can right click on you folder and click \"Copy Path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory with calibration data\n",
    "dir_cal_substrate = \"calibration/p_courmaric\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Calibration\n",
    "\n",
    "Let's begin by creating a calibration. Therefore we read in the calibration data. Depending in what format/from what machine your calibration Data are coming the method looks slightly different.\n",
    "We do this by instantialting a ```ChromAnalyzer``` Object though the Method .read_csv. If your calibration Data are in a different format the Method could also be ```.read_asm```, ```read_chromeleon```, ```read_thermo```, ```read_agilent```, etc.\n",
    "\n",
    "##### Furthermore we have to specify additional parameters for the method:\n",
    "1. ```path```:  Path to the directory in which your files are placed. Try to order them Alphabetically! In our case we have 3 files containing Measurements of 2mM, 4mM and 10mM of Substrate\n",
    "2. ```ph``` : pH of Measurement\n",
    "3. ```temperature``` : Experimental Tempertaure \n",
    "4. ```temperature_unit:``` Celsius -> \"C\"\n",
    "5. ```values```: In this case these are the concentration of each file. Since we have 3 files of different conditions, this list hast to have 3 values: [2, 4, 10]\n",
    "6. ```unit```: Unit of used concentration:\n",
    "7. ```mode```: Depending if your measurement is a \"calibration\" or \"time-course\".\n",
    "8. ```retention_time_col_name```: The CSV has different columns. write the name of the column of the retentiontime\n",
    "9. ```peak_area_col_name```: Here you should write the column name of the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read calibration data\n",
    "calibration_p_coumaric = ChromAnalyzer.read_csv(\n",
    "    path=dir_cal_substrate,\n",
    "    ph=7.4,\n",
    "    temperature=25,\n",
    "    temperature_unit=\"C\",\n",
    "    values=[2, 4, 10],\n",
    "    unit=\"mmol/ml\",\n",
    "    mode=\"calibration\",\n",
    "    retention_time_col_name=\"RetTime\",\n",
    "    peak_area_col_name=\"Area\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. In the next step we define the molecules of this Measurement:\n",
    "\n",
    "We define the molecoles of our \"calibration_p_coumaric\" ```ChromAnalyzer``` Object. Therefore we call the function ```.define_molecule()``` on the Object.\n",
    "We define Molecules with:\n",
    "- ```id``` = Our chosen ID of the Molecule. Remember it, because we need it later.\n",
    "- ```pubchem_cid``` = The Pubchem id is important. We fetch the info like its common name from the Database and assign it to the data.\n",
    "- ```retention_time```= Where do you expect the peak of your Molecule. Whats your retention time.\n",
    "- ```retention_tolerance``` = Here you define the time you expect your  molecule to become visable to the detector\n",
    "- ```wavelength``` = At which Wavelength is you Molecule Measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Assigned p-Coumaric acid to 3 peaks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define \n",
    "mol_PCA = calibration_p_coumaric.define_molecule(\n",
    "    id=\"PCA\",\n",
    "    pubchem_cid=\"637542\",\n",
    "    retention_time=1.5,\n",
    "    retention_tolerance=0.2,\n",
    "    wavelength=282\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we want to Visualize our data and inspect, how good our regression fits to the data.\n",
    "We call the ```add_standard()``` Function.\n",
    "- With ```molecule``` we specify what molecule we want to Vizuallize\n",
    "- With ```vizualize``` = True or False we turn on/off the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit  peaks to linear model\n",
    "calibration_p_coumaric.add_standard(\n",
    "    molecule=mol_PCA,\n",
    "    visualize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save for later yous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "mol_PCA.save_json(\"calibration/PCA_Molecule_Data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it for Vinylphenol!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First set up the path of your data:\n",
    "You can right click on you folder and click \"Copy Path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cal_product = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Calibration\n",
    "\n",
    "Let's make a calibration for vinylphenol. Therefore we read in the calibration data. Depending in what format/from what machine your calibration Data are coming the method looks slightly different.\n",
    "We do this by creating a ```ChromAnalyzer``` Object though the Method .read_csv. If your calibration Data are in a different format the Method could also be ```.read_asm```, ```read_chromeleon```, ```read_thermo```, ```read_agilent```, ```read_csv``` etc.\n",
    "\n",
    "##### Furthermore we have to specify additional parameters for the method:\n",
    "1. ```path```:  Path to the directory in which your files are placed. Try to order them Alphabetically! In our case we have 3 files containing Measurements of 2mM, 4mM and 10mM of Substrate\n",
    "2. ```ph``` : pH of Measurement\n",
    "3. ```temperature``` : Experimental Tempertaure \n",
    "4. ```temperature_unit:``` Celsius -> C\n",
    "5. ```values```: In this case these are the concentration of each file. Since we have 3 files of different conditions, this list hast to have 3 values: [2, 4, 10]\n",
    "6. ```unit```: Unit of used concentration:\n",
    "7. ```mode```: Depending if your measurement is a \"calibration\" or \"timecourse\".\n",
    "8. ```retention_time_col_name```: The CSV has different columns. write the name of the column of the retentiontime\n",
    "9. ```peak_area_col_name```: Here you should write the column name of the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read calibration data\n",
    "calibration_vinylphenol = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. In the next step we define the molecules of this Measurement:\n",
    "\n",
    "We define the molecoles of our \"calibration_vinylphenol\" ```ChromanAnalyzer``` Object. Therefore we call the function ```.define_molecule()``` on the Object.\n",
    "We define Molecules with:\n",
    "- ```id``` = Our chosen ID of the Molecule. Remember it, because we need it later.\n",
    "- ```pubchem_cid``` = The Pubchem id is important. We fetch the info like its common name from the Database and assign it to the data.\n",
    "- ```retention_time```= Where do you expect the peak of your Molecule. Whats your retention time.\n",
    "- ```retention_tolerance``` = Here you define the time you expect your  molecule to become visable to the detector\n",
    "- ```wavelength``` = At which Wavelength is you Molecule Measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \n",
    "mol_vinylphenol = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we want to Visualize our data and inspect, how good our regression fits to the data.\n",
    "We call the ```add_standard()``` Function.\n",
    "- With ```molecule``` we specify what molecule we want to Vizuallize\n",
    "- With ```vizualize``` = True or False we turn on/off the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit peaks to linear model\n",
    "calibration_vinylphenol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timecourse Data\n",
    "\n",
    "Now it's time to analyze your actual measurements (time course data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Timecourse\n",
    "Just as the calibration, the function calls the same function on the ChromAnalyzer object.\n",
    "We do this by instantialting a CromeAnalyzer Object though the Method ```.read_csv``` ```.read_asm```, ```read_chromeleon```, ```read_thermo```, ```read_agilent```, etc.\n",
    "\n",
    "##### Furthermore we have to specify additional parameters for the method:\n",
    "1. ```path```:  Path to the directory in which your files are placed. Try to order them Alphabetically! In our case we have 3 files containing Measurements of 2mM, 4mM and 10mM of Substrate\n",
    "2. ```ph``` : pH of Measurement\n",
    "3. ```temperature``` : Experimental Tempertaure \n",
    "4. ```temperature_unit:``` Celsius -> C\n",
    "5. ```values```: In this case these are the concentration of each file. Since we have 3 files of different conditions, this list hast to have 3 values: [2, 4, 10]\n",
    "6. ```unit```: Unit of used concentration:\n",
    "7. ```mode```: __This time use timecourse__\n",
    "\n",
    "8. ```retention_time_col_name```: The CSV has different columns. write the name of the column of the retentiontime\n",
    "9. ```peak_area_col_name```: Here you should write the column name of the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"measurement_data\"\n",
    "time_values = [0, 15, 30, 60, 120, 240]\n",
    "\n",
    "time_course = ChromAnalyzer.read_csv(\n",
    "    path=data_path,\n",
    "    ph=7.4,\n",
    "    temperature=25,\n",
    "    temperature_unit=\"C\",\n",
    "    mode=\"timecourse\",\n",
    "    values=time_values,\n",
    "    unit=\"minute\",\n",
    "    retention_time_col_name=\"RetTime\",\n",
    "    peak_area_col_name=\"Area\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromatopy import Molecule, to_enzymeml\n",
    "PCA_path = \"calibration/PCA_Molecule_Data.json\"\n",
    "mol_PCA = Molecule.read_json(PCA_path)\n",
    "\n",
    "#Change for your actual experiment\n",
    "#mol_PCA.retention_time = 1.5\n",
    "#mol_PCA.retention_tolerance = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Assigned p-Coumaric acid to 6 peaks\n"
     ]
    }
   ],
   "source": [
    "time_course.add_molecule(\n",
    "    molecule=mol_PCA,\n",
    "    init_conc=30,\n",
    "    conc_unit=\"mmol/ml\",\n",
    "    retention_tolerance=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it for vinylphenol!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Assigned 4-Vinylphenol to 5 peaks\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the information of your protein/peptide to your measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_course.define_protein(\n",
    "    id=\"PAD\",\n",
    "    name=\"Phenolic acid decarboxylase\",\n",
    "    init_conc=38.8,\n",
    "    conc_unit=\"mg/ml\",\n",
    "    sequence=\"BLADV\",\n",
    "    organism=\"Baci1\",\n",
    "    organism_tax_id=\"NCBI-TAXID\",\n",
    "    constant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dilution factor, if you had to dilute for measurement\n",
    "Here dilution was 1:10, so we set the factor to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_course.set_dilution_factor(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3018/506263778.py:1: DeprecationWarning: The to_enzymeml method is deprecated and will be removed in version 1.0.0. Use chromatopy.ioutils.enzymeml.to_enzymeml instead.\n",
      "  time_enzymeml = time_course.to_enzymeml(\n"
     ]
    }
   ],
   "source": [
    "time_enzymeml = time_course.to_enzymeml(\n",
    "    name=\"PCA_TimeCourse\",\n",
    "    calculate_concentration=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_enzymeml(time_enzymeml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data as EnzymeML Document\n",
    "enzyme_ml = to_enzymeml(\n",
    "    analyzers=[time_course],\n",
    "    document_name=\"2025_05_20_PAD_Time_course\",\n",
    "    calculate_concentration=True,\n",
    "    extrapolate=False,\n",
    ")\n",
    "\n",
    "# save EnzymeML Document to file\n",
    "with open(\"enzymeML_documents/2025_05_20_PAD_Time_course.json\", \"w\") as f:\n",
    "    f.write(enzyme_ml.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your helper function\n",
    "def get_time_and_data_by_species(doc, species_id):\n",
    "    for measurement in doc.measurements:\n",
    "        for data_entry in measurement.species_data:\n",
    "            if data_entry.species_id == species_id:\n",
    "                return data_entry.time, data_entry.data\n",
    "    return [], []\n",
    "\n",
    "def get_df_by_species(doc, species_id, column_name):\n",
    "    time, data = get_time_and_data_by_species(doc, species_id)\n",
    "    return pd.DataFrame({\"Time (min)\": time, column_name: data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual dataframes\n",
    "df_pca = get_df_by_species(time_enzymeml, \"PCA\", \"PCA (mmol/ml)\")\n",
    "df_vp = get_df_by_species(time_enzymeml, \"VINYLPHENOL\", \"4-Vinylphenol (mmol/ml)\")\n",
    "df_pad = get_df_by_species(time_enzymeml, \"PAD\", \"PAD (mg/ml)\")\n",
    "\n",
    "# Merge on Time using outer join to keep all time points\n",
    "df_combined = df_pca.merge(df_vp, on=\"Time (min)\", how=\"outer\")\n",
    "df_combined = df_combined.merge(df_pad, on=\"Time (min)\", how=\"outer\")\n",
    "\n",
    "# Sort by time just in case\n",
    "df_combined = df_combined.sort_values(\"Time (min)\")\n",
    "\n",
    "# Export to Excel\n",
    "df_combined.to_excel(\"enzyme_measurements.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined[\"PCA (mmol/ml)\"time_course.add_molecule(\n",
    "    molecule=mol_vinylphenol,\n",
    "    init_conc=0,\n",
    "    conc_unit=\"mmol/ml\",\n",
    "    retention_tolerance=0.1,\n",
    ")\n",
    "])\n",
    "print(df_combined[\"Time (min)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_min = df_combined[\"Time (min)\"].to_numpy()\n",
    "substrate_data = df_combined[\"PCA (mmol/ml)\"].to_numpy()\n",
    "S0 = substrate_data[0]\n",
    "\n",
    "# ODE: Michaelis-Menten\n",
    "def mm_ode(t, S, Vmax, Km):\n",
    "    return [-Vmax * S[0] / (Km + S[0])]\n",
    "\n",
    "# Simuliere das Modell (auf Messzeitpunkten fÃ¼r Fitting)\n",
    "def simulate_model(t_eval, Vmax, Km):\n",
    "    sol = solve_ivp(mm_ode, (t_eval[0], t_eval[-1]), [S0],\n",
    "                    t_eval=t_eval, args=(Vmax, Km), method='LSODA',\n",
    "                    rtol=1e-8, atol=1e-10)\n",
    "    return sol.y[0]\n",
    "\n",
    "# Define residuals function for least squares fitting\n",
    "def residuals(params):\n",
    "    Vmax, Km = params\n",
    "    S_sim = simulate_model(time_min, Vmax, Km)\n",
    "    return S_sim - substrate_data\n",
    "\n",
    "# Fit\n",
    "initial_guess = [0.01, 10]\n",
    "bounds = ([1e-6, 1e-3], [10, 1000])\n",
    "result = least_squares(residuals, initial_guess, bounds=bounds)\n",
    "Vmax_fit, Km_fit = result.x\n",
    "\n",
    "# Glatte Kurve berechnen\n",
    "time_fine = np.linspace(0, 240, 500)\n",
    "S_fit_fine = simulate_model(time_fine, Vmax_fit, Km_fit)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_min, substrate_data, 'o', label='Concentration p-coumaric acid')\n",
    "plt.plot(time_fine, S_fit_fine, '-', label='Fitted Michaelis Menten')\n",
    "plt.xlabel(\"Time (min)\")\n",
    "plt.ylabel(\"Substrate (mmol/ml)\")\n",
    "plt.title(\"Michaelis-Menten Fit (ODE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Ergebnis\n",
    "print(f\"Vmax = {Vmax_fit:.6f} mmol/ml/min\")\n",
    "print(f\"Km   = {Km_fit:.3f} mmol/ml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate for example Kcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kcat\n",
    "enzyme_conc_mg_ml = 38.8\n",
    "enzyme_mw_kDa = 57.52\n",
    "enzyme_conc_mol_L = (enzyme_conc_mg_ml / 1000) / (enzyme_mw_kDa * 1000)\n",
    "kcat = Vmax_fit / enzyme_conc_mol_L\n",
    "print(f\"Kcat for this enzyme is {kcat} 1/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Global Fit of Michaelis-Menten Kinetics Using Triplicate Data\n",
    "\n",
    "This script demonstrates how to simulate, fit, and visualize an enzyme kinetics experiment based on the **Michaelis-Menten equation**, using triplicate experimental data and parameter estimation with **confidence intervals**.\n",
    "\n",
    "\n",
    "\n",
    "#Imports\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "```\n",
    "\n",
    "We use common scientific libraries:\n",
    "\n",
    "* `numpy`, `pandas` for data handling\n",
    "* `matplotlib` for plotting\n",
    "* `scipy` for solving differential equations and optimization\n",
    "\n",
    "\n",
    "\n",
    "## Michaelis-Menten ODE\n",
    "\n",
    "```python\n",
    "def mm_ode(t, S, Vmax, Km):\n",
    "    return [-Vmax * S[0] / (Km + S[0])]\n",
    "```\n",
    "\n",
    "This function defines the **Michaelis-Menten differential equation** describing how substrate concentration `S` changes over time.\n",
    "\n",
    "* `Vmax`: maximum reaction rate\n",
    "* `Km`: Michaelis constant\n",
    "\n",
    "---\n",
    "\n",
    "## Simulate Model\n",
    "\n",
    "```python\n",
    "def simulate_model(t_eval, S0, Vmax, Km):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Solves the ODE numerically over a time grid `t_eval`, starting from initial substrate concentration `S0`.\n",
    "\n",
    "---\n",
    "\n",
    "## Create Triplicate Data\n",
    "\n",
    "```python\n",
    "def create_triplicate_data():\n",
    "    ...\n",
    "```\n",
    "\n",
    "This function simulates **3 experimental replicates**:\n",
    "\n",
    "1. It adds **random noise** to simulate experimental variability.\n",
    "2. Returns a list of DataFrames, one per replicate.\n",
    "\n",
    "---\n",
    "\n",
    "## Residual Function\n",
    "\n",
    "```python\n",
    "def global_residuals(params, replicates):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Defines the **difference between model and data** (residuals). This is minimized during the fitting process to find the best `Vmax` and `Km`.\n",
    "\n",
    "---\n",
    "\n",
    "## Fit Parameters Globally\n",
    "\n",
    "```python\n",
    "result = least_squares(...)\n",
    "```\n",
    "\n",
    "* Fits **all replicates simultaneously**.\n",
    "* Uses nonlinear least squares optimization.\n",
    "* Applies **bounds** to ensure realistic values.\n",
    "\n",
    "Extracts:\n",
    "\n",
    "* Fitted parameters: `Vmax_fit`, `Km_fit`\n",
    "* **Covariance matrix** â†’ used to estimate uncertainty in parameters\n",
    "* 95% **confidence intervals**\n",
    "\n",
    "---\n",
    "\n",
    "## Confidence Interval Sampling\n",
    "\n",
    "```python\n",
    "param_samples = np.random.multivariate_normal(...)\n",
    "```\n",
    "\n",
    "* Samples 300 parameter combinations from a **multivariate normal distribution** based on the fitted parameter uncertainties.\n",
    "* Simulates model curves for each sample to create a **confidence band**.\n",
    "\n",
    "---\n",
    "\n",
    "## Plotting Results\n",
    "\n",
    "```python\n",
    "plt.plot(...)\n",
    "```\n",
    "\n",
    "* Plots all 3 replicates as points.\n",
    "* Shows the **best-fit curve**.\n",
    "* Adds a **95% confidence band** around the fit.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Output\n",
    "\n",
    "```text\n",
    "Global Fit:\n",
    "Vmax = 0.020000 Â± 0.001234 mmol/ml/min\n",
    "Km   = 15.000 Â± 0.678 mmol/ml\n",
    "```\n",
    "\n",
    "You get both parameter estimates and their uncertainties, visualized in the final plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ODE\n",
    "def mm_ode(t, S, Vmax, Km):\n",
    "    return [-Vmax * S[0] / (Km + S[0])]\n",
    "\n",
    "def simulate_model(t_eval, S0, Vmax, Km):\n",
    "    sol = solve_ivp(mm_ode, (t_eval[0], t_eval[-1]), [S0],\n",
    "                    t_eval=t_eval, args=(Vmax, Km), method='LSODA',\n",
    "                    rtol=1e-8, atol=1e-10)\n",
    "    return sol.y[0]\n",
    "\n",
    "# Triplikat-Daten\n",
    "def create_triplicate_data():\n",
    "    np.random.seed(42)\n",
    "    time_min = np.array([0, 15, 30, 60, 120, 240])\n",
    "    Vmax_true = 0.02\n",
    "    Km_true = 15\n",
    "    S0_true = 0.5\n",
    "\n",
    "    dfs = []\n",
    "    for i in range(3):\n",
    "        clean = simulate_model(time_min, S0_true, Vmax_true, Km_true)\n",
    "        noisy = clean + np.random.normal(0, 0.01, size=clean.shape)\n",
    "        df = pd.DataFrame({\n",
    "            \"Time (min)\": time_min,\n",
    "            \"PCA (mmol/ml)\": noisy,\n",
    "            \"Replicate\": f\"R{i+1}\"\n",
    "        })\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "# Residuen\n",
    "def global_residuals(params, replicates):\n",
    "    Vmax, Km = params\n",
    "    res = []\n",
    "    for df in replicates:\n",
    "        t = df[\"Time (min)\"].to_numpy()\n",
    "        y = df[\"PCA (mmol/ml)\"].to_numpy()\n",
    "        S0 = y[0]\n",
    "        model = simulate_model(t, S0, Vmax, Km)\n",
    "        res.append(model - y)\n",
    "    return np.concatenate(res)\n",
    "\n",
    "# Hauptteil\n",
    "replicates = create_triplicate_data()\n",
    "all_data = pd.concat(replicates, ignore_index=True)\n",
    "\n",
    "# Fit\n",
    "initial_guess = [0.01, 10]\n",
    "bounds = ([1e-6, 1e-3], [10, 1000])\n",
    "result = least_squares(global_residuals, initial_guess, bounds=bounds, args=(replicates,))\n",
    "Vmax_fit, Km_fit = result.x\n",
    "\n",
    "# Kovarianzmatrix und Unsicherheiten\n",
    "J = result.jac\n",
    "residuals = result.fun\n",
    "n = len(residuals)\n",
    "p = len(result.x)\n",
    "residual_var = np.sum(residuals**2) / (n - p)\n",
    "cov = residual_var * np.linalg.inv(J.T @ J)\n",
    "se = np.sqrt(np.diag(cov))\n",
    "ci_95 = 1.96 * se\n",
    "\n",
    "print(f\"Global Fit:\")\n",
    "print(f\"Vmax = {Vmax_fit:.6f} Â± {ci_95[0]:.6f} mmol/ml/min\")\n",
    "print(f\"Km   = {Km_fit:.3f} Â± {ci_95[1]:.3f} mmol/ml\")\n",
    "\n",
    "# Konfidenzbereich durch Parametersampling\n",
    "N_samples = 300\n",
    "param_samples = np.random.multivariate_normal([Vmax_fit, Km_fit], cov, N_samples)\n",
    "\n",
    "# Simuliere Fit-Kurven\n",
    "t_fine = np.linspace(0, 240, 300)\n",
    "S0_mean = all_data.groupby(\"Replicate\").first()[\"PCA (mmol/ml)\"].mean()\n",
    "S_bands = []\n",
    "\n",
    "for Vmax_s, Km_s in param_samples:\n",
    "    S_sample = simulate_model(t_fine, S0_mean, Vmax_s, Km_s)\n",
    "    S_bands.append(S_sample)\n",
    "\n",
    "S_bands = np.array(S_bands)\n",
    "S_lower = np.percentile(S_bands, 2.5, axis=0)\n",
    "S_upper = np.percentile(S_bands, 97.5, axis=0)\n",
    "S_fit = simulate_model(t_fine, S0_mean, Vmax_fit, Km_fit)\n",
    "\n",
    "# Plot alles zusammen\n",
    "plt.figure(figsize=(8, 5))\n",
    "for label, grp in all_data.groupby(\"Replicate\"):\n",
    "    plt.plot(grp[\"Time (min)\"], grp[\"PCA (mmol/ml)\"], 'o', label=label)\n",
    "\n",
    "plt.plot(t_fine, S_fit, 'k-', lw=2, label='Globaler Fit')\n",
    "plt.fill_between(t_fine, S_lower, S_upper, color='gray', alpha=0.3, label='95% Konfidenzband')\n",
    "\n",
    "plt.xlabel(\"Zeit (min)\")\n",
    "plt.ylabel(\"PCA (mmol/ml)\")\n",
    "plt.title(\"Globaler Michaelis-Menten-Fit mit Konfidenzbereich (Triplikat)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromatopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
